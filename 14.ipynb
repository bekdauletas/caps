{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgEheCqEoCui",
        "outputId": "7c5896b6-0dc3-4305-ce4a-19aaa7f0c268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data with 16 records\n",
            "First few rows:\n",
            "   Unnamed: 0  Case  Stratum  Cluster  Variable\n",
            "0         NaN     1        1        1      11.5\n",
            "1         NaN     2        1        1      29.0\n",
            "2         NaN     3        1        2      35.6\n",
            "3         NaN     4        1        2      64.7\n",
            "4         NaN     5        2        3      19.2\n",
            "\n",
            "==== Simple Random Sampling Analysis ====\n",
            "1) Mean (SRS): 50.60\n",
            "2) Standard Error (SRS): 6.8851\n",
            "3) 95% Confidence Interval (SRS):\n",
            "   Upper limit: 64.6455\n",
            "   Lower limit: 36.5545\n",
            "\n",
            "==== Clustered Random Sampling Analysis ====\n",
            "1) Mean (Clustered): 50.60\n",
            "2) Standard Error (Clustered): 7.6243\n",
            "3) Design Effect (d-value): 1.1074\n",
            "4) d-squared: 1.2263\n",
            "5) Intraclass correlation (roh): 0.2263\n",
            "6) Effective sample size (Neff): 13.0477\n",
            "\n",
            "==== Summary of Results (Rounded as Required) ====\n",
            "srs_mean: 50.6\n",
            "srs_se: 6.8851\n",
            "ci_upper: 64.6455\n",
            "ci_lower: 36.5545\n",
            "crs_mean: 50.6\n",
            "crs_se: 7.6243\n",
            "d_value: 1.1074\n",
            "d_squared: 1.2263\n",
            "roh: 0.2263\n",
            "Neff: 13.0477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#1 task\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        data = pd.read_excel(file_path, engine='openpyxl')\n",
        "        print(f\"Successfully loaded data with {len(data)} records\")\n",
        "        print(\"First few rows:\")\n",
        "        print(data.head())\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Excel file: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "def prepare_data(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    required_columns = ['Case', 'Stratum', 'Cluster', 'Variable']\n",
        "    for column in required_columns:\n",
        "        if column not in data.columns:\n",
        "            print(f\"Error: '{column}' column not found in the dataset.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    data['response'] = data['Variable']\n",
        "    data['cluster_id'] = data['Cluster']\n",
        "    return data\n",
        "\n",
        "\n",
        "def simple_random_sampling(data: pd.DataFrame) -> Dict[str, float]:\n",
        "    print(\"\\n==== Simple Random Sampling Analysis ====\")\n",
        "    srs_mean = data['response'].mean()\n",
        "    print(f\"1) Mean (SRS): {srs_mean:.2f}\")\n",
        "\n",
        "    n = len(data)\n",
        "    srs_std = data['response'].std(ddof=1)\n",
        "    srs_se = srs_std / np.sqrt(n)\n",
        "    print(f\"2) Standard Error (SRS): {srs_se:.4f}\")\n",
        "\n",
        "    t_value = 2.04\n",
        "    margin_of_error = t_value * srs_se\n",
        "    ci_upper = srs_mean + margin_of_error\n",
        "    ci_lower = srs_mean - margin_of_error\n",
        "    print(f\"3) 95% Confidence Interval (SRS):\")\n",
        "    print(f\"   Upper limit: {ci_upper:.4f}\")\n",
        "    print(f\"   Lower limit: {ci_lower:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'srs_mean': srs_mean,\n",
        "        'srs_se': srs_se,\n",
        "        'ci_upper': ci_upper,\n",
        "        'ci_lower': ci_lower\n",
        "    }\n",
        "\n",
        "\n",
        "def clustered_random_sampling(data: pd.DataFrame, srs_se: float) -> Dict[str, float]:\n",
        "    print(\"\\n==== Clustered Random Sampling Analysis ====\")\n",
        "    cluster_means = data.groupby('cluster_id')['response'].mean()\n",
        "    crs_mean = cluster_means.mean()\n",
        "    print(f\"1) Mean (Clustered): {crs_mean:.2f}\")\n",
        "\n",
        "    M = len(cluster_means)\n",
        "    cluster_var = np.var(cluster_means, ddof=1)\n",
        "    crs_se = np.sqrt(cluster_var / M)\n",
        "    print(f\"2) Standard Error (Clustered): {crs_se:.4f}\")\n",
        "\n",
        "    d_value = crs_se / srs_se\n",
        "    print(f\"3) Design Effect (d-value): {d_value:.4f}\")\n",
        "\n",
        "    d_squared = d_value ** 2\n",
        "    print(f\"4) d-squared: {d_squared:.4f}\")\n",
        "\n",
        "    n_avg = data.groupby('cluster_id').size().mean()\n",
        "    roh = (d_squared - 1) / (n_avg - 1) if n_avg > 1 else 0\n",
        "    print(f\"5) Intraclass correlation (roh): {roh:.4f}\")\n",
        "\n",
        "    Neff = len(data) / d_squared\n",
        "    print(f\"6) Effective sample size (Neff): {Neff:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'crs_mean': crs_mean,\n",
        "        'crs_se': crs_se,\n",
        "        'd_value': d_value,\n",
        "        'd_squared': d_squared,\n",
        "        'roh': roh,\n",
        "        'Neff': Neff\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_comparison(srs_mean: float, crs_mean: float, srs_se: float, crs_se: float):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(['SRS Mean', 'Clustered Mean'], [srs_mean, crs_mean])\n",
        "    plt.errorbar(['SRS Mean', 'Clustered Mean'], [srs_mean, crs_mean],\n",
        "                 yerr=[srs_se, crs_se], fmt='o', color='black')\n",
        "    plt.title('Comparison of SRS and Clustered Random Sampling')\n",
        "    plt.ylabel('Mean Value')\n",
        "    plt.savefig('sampling_comparison.png')\n",
        "\n",
        "\n",
        "def analyze_survey_data(excel_file_path: str) -> Dict[str, Any]:\n",
        "    data = load_data(excel_file_path)\n",
        "    if data.empty:\n",
        "        return {}\n",
        "\n",
        "    data = prepare_data(data)\n",
        "    if data.empty:\n",
        "        return {}\n",
        "\n",
        "    srs_results = simple_random_sampling(data)\n",
        "    crs_results = clustered_random_sampling(data, srs_results['srs_se'])\n",
        "\n",
        "    plot_comparison(srs_results['srs_mean'], crs_results['crs_mean'],\n",
        "                    srs_results['srs_se'], crs_results['crs_se'])\n",
        "\n",
        "    results = {**srs_results, **crs_results}\n",
        "    return {k: round(v, 4) for k, v in results.items()}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = analyze_survey_data('Question1_Final_CP.xlsx')\n",
        "    if results:\n",
        "        print(\"\\n==== Summary of Results (Rounded as Required) ====\")\n",
        "        for key, value in results.items():\n",
        "            print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 task\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the dataset from CSV file (use the filename as is, since it's in the same directory)\n",
        "data = pd.read_csv('Question2_Dataset.csv')\n",
        "\n",
        "# Prepare the features (X) and target (y)\n",
        "X = data[['X1', 'X2', 'X1^2', 'X1^3', 'X2^2', 'X2^3', 'X1*X2', 'X1^2*X2']].values\n",
        "y = data['Y'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the features (Z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_normalized, y)\n",
        "\n",
        "# Get the initial theta parameters (including bias)\n",
        "initial_theta = np.zeros(X.shape[1] + 1)  # +1 for bias term (9 parameters total: 1 bias + 8 features)\n",
        "theta = np.concatenate([model.intercept_, model.coef_.flatten()])\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "# Function to calculate cost (Mean Squared Error)\n",
        "def calculate_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    predictions = X.dot(theta[1:]) + theta[0]  # Shape: (m,)\n",
        "    cost = (1 / (2 * m)) * np.sum((predictions - y.flatten()) ** 2)\n",
        "    return cost\n",
        "\n",
        "\n",
        "# Gradient descent implementation\n",
        "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
        "    m = len(y)  # Number of samples\n",
        "    n = X.shape[1]  # Number of features\n",
        "    cost_history = []\n",
        "\n",
        "    # Ensure y is flattened to avoid shape mismatch\n",
        "    y = y.flatten()  # Now y has shape (m,)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Calculate predictions (shape: (m,))\n",
        "        predictions = X.dot(theta[1:]) + theta[0]  # theta[1:] has shape (n,), X has shape (m,n)\n",
        "        errors = predictions - y  # Shape: (m,)\n",
        "\n",
        "        # Update bias (theta[0]) - sum over all examples\n",
        "        theta[0] = theta[0] - (learning_rate / m) * np.sum(errors)\n",
        "\n",
        "        # Update feature coefficients (theta[1:]) - calculate gradient correctly\n",
        "        gradient_features = (1 / m) * X.T.dot(errors)  # Shape: (n,) where n=8\n",
        "        theta[1:] = theta[1:] - learning_rate * gradient_features  # Both shapes (n,)\n",
        "\n",
        "        cost = calculate_cost(X, y, theta)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "# Run gradient descent for different iterations\n",
        "n_10_results = gradient_descent(X_normalized, y, initial_theta.copy(), learning_rate, 10)\n",
        "n_100_results = gradient_descent(X_normalized, y, initial_theta.copy(), learning_rate, 100)\n",
        "n_1000_results = gradient_descent(X_normalized, y, initial_theta.copy(), learning_rate, 1000)\n",
        "\n",
        "# Print results in the required format (rounded to integers)\n",
        "print(\"n=10\")\n",
        "print(\"Cost Function (Round):\", round(calculate_cost(X_normalized, y, n_10_results[0])))\n",
        "print(\"Optimal Theta parameter (Round):\", [round(x) for x in n_10_results[0]])\n",
        "\n",
        "print(\"\\nn=100\")\n",
        "print(\"Cost Function (Round):\", round(calculate_cost(X_normalized, y, n_100_results[0])))\n",
        "print(\"Optimal Theta parameter (Round):\", [round(x) for x in n_100_results[0]])\n",
        "\n",
        "print(\"\\nn=1000\")\n",
        "print(\"Cost Function (Round):\", round(calculate_cost(X_normalized, y, n_1000_results[0])))\n",
        "print(\"Optimal Theta parameter (Round):\", [round(x) for x in n_1000_results[0]])\n"
      ],
      "metadata": {
        "id": "-cgd06CkgADz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "n=10\n",
        "Cost Function (Round): 895241\n",
        "Optimal Theta parameter (Round): [2167, -54, 839, -47, -31, 1001, 1080, 436, 283]\n",
        "\n",
        "n=100\n",
        "Cost Function (Round): 42271\n",
        "Optimal Theta parameter (Round): [3328, 50, 230, 125, 192, 1244, 1897, 18, 63]\n",
        "\n",
        "n=1000\n",
        "Cost Function (Round): 1261\n",
        "Optimal Theta parameter (Round): [3328, -17, -520, 119, 228, 1231, 2651, -64, 200]\n"
      ],
      "metadata": {
        "id": "KRCFY1LNiXBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3 task\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the dataset from CSV file\n",
        "data = pd.read_csv('Question3_Final_CP.csv')\n",
        "\n",
        "# Prepare the features (X) and target (y)\n",
        "X = data[['X1', 'X2', 'X3']].values  # 3 input features\n",
        "y = data['Y'].values.reshape(-1, 1)  # Binary output (0 or 1)\n",
        "\n",
        "# Normalize the features (Z-score normalization: Z = (X - mu)/std)\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Add intercept term (bias) to X\n",
        "X_normalized = np.c_[np.ones(X_normalized.shape[0]), X_normalized]  # Shape: (n_samples, 4) with bias\n",
        "\n",
        "# Initial theta parameters (0 for all, including bias)\n",
        "n_features = X_normalized.shape[1]  # 4 (1 bias + 3 features)\n",
        "theta = np.zeros((n_features, 1))  # Initial theta 2D: [[0], [0], [0], [0]]\n",
        "\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "# Cost function with L2 regularization\n",
        "def compute_cost(X, y, theta, lambda_reg):\n",
        "    m = len(y)\n",
        "    h = sigmoid(X.dot(theta))  # Predictions\n",
        "    # Cost without regularization\n",
        "    cost = (-1 / m) * (y.T.dot(np.log(h + 1e-15)) + (1 - y).T.dot(np.log(1 - h + 1e-15)))\n",
        "    # Add L2 regularization (ridge) - exclude theta[0] (bias) from regularization\n",
        "    reg_term = (lambda_reg / (2 * m)) * np.sum(theta[1:] ** 2)\n",
        "    return cost[0][0] + reg_term  # Return scalar\n",
        "\n",
        "\n",
        "# Gradient descent with L2 regularization\n",
        "def gradient_descent(X, y, theta, alpha, lambda_reg, iterations):\n",
        "    m = len(y)\n",
        "    cost_history = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        h = sigmoid(X.dot(theta))  # Predictions\n",
        "        # Gradient without regularization\n",
        "        gradient = (1 / m) * X.T.dot(h - y)  # Shape: (n_features, 1)\n",
        "        # Add L2 regularization gradient (exclude theta[0])\n",
        "        gradient[1:] += (lambda_reg / m) * theta[1:]\n",
        "        # Update theta\n",
        "        theta = theta - alpha * gradient\n",
        "        cost = compute_cost(X, y, theta, lambda_reg)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "# Parameters for different cases\n",
        "cases = [\n",
        "    (100, 0.1, 0.1),  # N=100, alpha=0.1, lambda=0.1\n",
        "    (1000, 0.2, 1),  # N=1000, alpha=0.2, lambda=1\n",
        "    (10000, 0.3, 10)  # N=10000, alpha=0.3, lambda=10\n",
        "]\n",
        "\n",
        "# Run logistic regression for each case\n",
        "for n_iterations, alpha, lambda_reg in cases:\n",
        "    theta_init = np.zeros((n_features, 1))\n",
        "    final_theta, _ = gradient_descent(X_normalized, y, theta_init, alpha, lambda_reg, n_iterations)\n",
        "\n",
        "    # Compute cost (rounded up to 2 decimal places after floating point)\n",
        "    cost = compute_cost(X_normalized, y, final_theta, lambda_reg)\n",
        "    cost_rounded = round(cost, 2)  # Round to 2 decimal places\n",
        "\n",
        "    # Find maximum theta value (rounded up to 2 decimal places after floating point)\n",
        "    max_theta = np.max(np.abs(final_theta))  # Use absolute value for maximum\n",
        "    max_theta_rounded = round(max_theta, 2)  # Round to 2 decimal places\n",
        "\n",
        "    print(f\"N={n_iterations}, alpha={alpha}, lambda={lambda_reg}\")\n",
        "    print(f\"Cost function (rounded up to 2 digits after floating point): {cost_rounded}\")\n",
        "    print(f\"Optimal theta parameter maximum value (rounded up to 2 digits after floating point): {max_theta_rounded}\\n\")\n",
        "\n",
        "# Special case: After 10,000 iterations, alpha=0.3, lambda=10, predict first 10 rows with threshold=0.5\n",
        "theta_final, _ = gradient_descent(X_normalized, y, np.zeros((n_features, 1)), 0.3, 10, 10000)\n",
        "predictions = sigmoid(X_normalized.dot(theta_final))  # Predict probabilities for all rows\n",
        "first_10_predictions = (predictions[:10] >= 0.5).astype(int)  # Apply threshold 0.5, convert to 0 or 1\n",
        "number_of_ones = np.sum(first_10_predictions)  # Count number of 1s in first 10 rows\n",
        "\n",
        "print(f\"Number of ones in the first 10 rows of predictions (threshold=0.5): {int(number_of_ones)}\")\n"
      ],
      "metadata": {
        "id": "JmjyJEvSia5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "N=100, alpha=0.1, lambda=0.1\n",
        "Cost function (rounded up to 2 digits after floating point): 0.28\n",
        "Optimal theta parameter maximum value (rounded up to 2 digits after floating point): 1.61\n",
        "\n",
        "N=1000, alpha=0.2, lambda=1\n",
        "Cost function (rounded up to 2 digits after floating point): 0.16\n",
        "Optimal theta parameter maximum value (rounded up to 2 digits after floating point): 4.59\n",
        "\n",
        "N=10000, alpha=0.3, lambda=10\n",
        "Cost function (rounded up to 2 digits after floating point): 0.33\n",
        "Optimal theta parameter maximum value (rounded up to 2 digits after floating point): 2.02\n",
        "\n",
        "Number of ones in the first 10 rows of predictions (threshold=0.5): 6"
      ],
      "metadata": {
        "id": "OMCbwdaXiqfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4 TASK\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "\n",
        "# Example input (flattened image vectors) - replace with your actual normalized data\n",
        "X = np.array([[0.25, 0.5, 0.75, 1.0],  # Dog image example (simplified)\n",
        "              [0.1, 0.3, 0.5, 0.7]])  # Cat image example (simplified)\n",
        "\n",
        "# Example output (1 for dog, 0 for cat)\n",
        "y = np.array([[1], [0]])\n",
        "\n",
        "# Network architecture\n",
        "input_layer_size = 4  # Number of features\n",
        "hidden_layer1_size = 7  # First hidden layer neurons\n",
        "hidden_layer2_size = 5  # Second hidden layer neurons\n",
        "hidden_layer3_size = 3  # Third hidden layer neurons\n",
        "output_layer_size = 1  # Binary classification (dog/cat)\n",
        "\n",
        "# Fixed initial weights and biases (as provided)\n",
        "W1 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
        "               [0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4],\n",
        "               [1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1],\n",
        "               [2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8]])\n",
        "b1 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]])\n",
        "\n",
        "W2 = np.array([[0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "               [0.7, 0.8, 0.9, 1.0, 1.1],\n",
        "               [1.2, 1.3, 1.4, 1.5, 1.6],\n",
        "               [1.7, 1.8, 1.9, 2.0, 2.1],\n",
        "               [2.2, 2.3, 2.4, 2.5, 2.6],\n",
        "               [2.7, 2.8, 2.9, 3.0, 3.1],\n",
        "               [3.2, 3.3, 3.4, 3.5, 3.6]])\n",
        "b2 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5]])\n",
        "\n",
        "W3 = np.array([[0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7],\n",
        "               [0.8, 0.9, 1.0],\n",
        "               [1.1, 1.2, 1.3],\n",
        "               [1.4, 1.5, 1.6]])\n",
        "b3 = np.array([[0.1, 0.2, 0.3]])\n",
        "\n",
        "W4 = np.array([[0.2], [0.3], [0.4]])\n",
        "b4 = np.array([[0.1]])\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Lists to store metrics for final analysis\n",
        "a4_history = []\n",
        "W4_history = []\n",
        "W3_history = []\n",
        "loss_history = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = tanh(z1)  # Tanh activation for hidden layer 1\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = tanh(z2)  # Tanh activation for hidden layer 2\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    a3 = tanh(z3)  # Tanh activation for hidden layer 3\n",
        "\n",
        "    z4 = np.dot(a3, W4) + b4\n",
        "    a4 = sigmoid(z4)  # Sigmoid activation for output layer\n",
        "\n",
        "    # Compute loss (Mean Absolute Error - MAE)\n",
        "    error = y - a4\n",
        "    loss = np.mean(np.abs(error))\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    # Store history for final analysis\n",
        "    a4_history.append(a4.copy())\n",
        "    W4_history.append(W4.copy())\n",
        "    W3_history.append(W3.copy())\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a4 = error * sigmoid_derivative(a4)  # Derivative of sigmoid for output layer\n",
        "    d_W4 = np.dot(a3.T, d_a4) * learning_rate\n",
        "    d_b4 = np.sum(d_a4, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    d_a3 = np.dot(d_a4, W4.T) * tanh_derivative(a3)  # Derivative of Tanh for hidden layer 3\n",
        "    d_W3 = np.dot(a2.T, d_a3) * learning_rate\n",
        "    d_b3 = np.sum(d_a3, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    d_a2 = np.dot(d_a3, W3.T) * tanh_derivative(a2)  # Derivative of Tanh for hidden layer 2\n",
        "    d_W2 = np.dot(a1.T, d_a2) * learning_rate\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * tanh_derivative(a1)  # Derivative of Tanh for hidden layer 1\n",
        "    d_W1 = np.dot(X.T, d_a1) * learning_rate\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Update weights and biases\n",
        "    W4 += d_W4\n",
        "    b4 += d_b4\n",
        "    W3 += d_W3\n",
        "    b3 += d_b3\n",
        "    W2 += d_W2\n",
        "    b2 += d_b2\n",
        "    W1 += d_W1\n",
        "    b1 += d_b1\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Final predictions (probabilities for each input)\n",
        "y_pred = a4\n",
        "print(\"Final Predictions:\", y_pred)\n",
        "\n",
        "# Compute required metrics after 10,000 epochs\n",
        "# a4 = [value1, value2, ...] (final activations of output layer, rounded to 3 decimal places)\n",
        "a4_final = a4_history[-1]  # Last activation values\n",
        "a4_rounded = np.round(a4_final, 3)  # Round to 3 digits after floating point\n",
        "print(f\"a4 = {a4_rounded.flatten().tolist()}\")\n",
        "\n",
        "# a3_min (minimum activation in hidden layer 3, rounded to 3 decimal places)\n",
        "a3_final = a3  # Final activations of hidden layer 3\n",
        "a3_min = np.min(a3_final)\n",
        "a3_min_rounded = round(a3_min, 3)  # Round to 3 digits after floating point\n",
        "print(f\"a3_min = {a3_min_rounded}\")\n",
        "\n",
        "# W4_max (maximum weight in W4, rounded to 2 decimal places)\n",
        "W4_max = np.max(np.abs(W4))  # Use absolute value for maximum\n",
        "W4_max_rounded = round(W4_max, 2)  # Round to 2 digits after floating point\n",
        "print(f\"W4_max = {W4_max_rounded}\")\n",
        "\n",
        "# W3_min (minimum weight in W3, rounded to 2 decimal places)\n",
        "W3_min = np.min(np.abs(W3))  # Use absolute value for minimum\n",
        "W3_min_rounded = round(W3_min, 2)  # Round to 2 digits after floating point\n",
        "print(f\"W3_min = {W3_min_rounded}\")\n",
        "\n",
        "# Loss after 10,000 epochs (rounded to 2 decimal places)\n",
        "loss_final = loss_history[-1]  # Last loss value\n",
        "loss_rounded = round(loss_final, 2)  # Round to 2 digits after floating point\n",
        "print(f\"Loss after 10000 epochs: {loss_rounded}\")\n",
        "\n",
        "# General Conclusion: Predict class for the inputs (dog or cat)\n",
        "threshold = 0.5\n",
        "predictions_binary = (y_pred >= threshold).astype(int)\n",
        "dog_pred = np.any(predictions_binary == 1)  # If any prediction is 1, predict dog\n",
        "cat_pred = np.any(predictions_binary == 0)  # If any prediction is 0, predict cat\n",
        "\n",
        "if dog_pred and not cat_pred:\n",
        "    conclusion = \"NN predicts image of dog\"\n",
        "elif cat_pred and not dog_pred:\n",
        "    conclusion = \"NN predicts image of cat\"\n",
        "else:\n",
        "    conclusion = \"NN can't define correct image class\"\n",
        "\n",
        "print(f\"General Conclusion after 10000 epochs: {conclusion}\")"
      ],
      "metadata": {
        "id": "mEjaD3itit5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Predictions: [[0.5]\n",
        " [0.5]]\n",
        "a4 = [0.5, 0.5]\n",
        "a3_min = 0.999\n",
        "W4_max = 0.15\n",
        "W3_min = 0.19\n",
        "Loss after 10000 epochs: 0.5\n",
        "General Conclusion after 10000 epochs: NN predicts image of dog\n"
      ],
      "metadata": {
        "id": "4YX29x_ziy18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5 task\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the dataset from CSV file\n",
        "data = pd.read_csv('Question5_Multi_Class_Dataset.csv')\n",
        "\n",
        "# Prepare the features (X) and target (y)\n",
        "X = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5']].values  # 5 input features\n",
        "y = data['Target'].values  # Output variable (0, 1, or 2)\n",
        "\n",
        "# Split the dataset: 70% training, 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression classifier\n",
        "clf_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf_lr.predict(X_test)\n",
        "\n",
        "# Compute metrics for each class (0, 1, 2)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1_class_0 = f1_score(y_test, y_pred, average=None, labels=[0])[0]  # F1 for class 0\n",
        "f1_class_1 = f1_score(y_test, y_pred, average=None, labels=[1])[0]  # F1 for class 1\n",
        "f1_class_2 = f1_score(y_test, y_pred, average=None, labels=[2])[0]  # F1 for class 2\n",
        "\n",
        "# Round all metrics to 3 decimal places\n",
        "accuracy_rounded = round(accuracy, 3)\n",
        "f1_class_0_rounded = round(f1_class_0, 3)\n",
        "f1_class_1_rounded = round(f1_class_1, 3)\n",
        "f1_class_2_rounded = round(f1_class_2, 3)\n",
        "\n",
        "# Print results for verification\n",
        "print(f\"Accuracy: {accuracy_rounded}\")\n",
        "print(f\"F-1 score (class = 0): {f1_class_0_rounded}\")\n",
        "print(f\"F-1 score (class = 1): {f1_class_1_rounded}\")\n",
        "print(f\"F-1 score (class = 2): {f1_class_2_rounded}\")\n",
        "\n",
        "# Convert metrics to strings for digit-by-digit output (for drag-and-drop)\n",
        "def digits_to_list(number):\n",
        "    number_str = f\"{number:.3f}\"  # Format to 3 decimal places\n",
        "    return [int(d) for d in number_str.replace('.', '')]  # Remove decimal and convert to list of integers\n",
        "\n",
        "# Get digits for each metric\n",
        "accuracy_digits = digits_to_list(accuracy_rounded)\n",
        "f1_class_0_digits = digits_to_list(f1_class_0_rounded)\n",
        "f1_class_1_digits = digits_to_list(f1_class_1_rounded)\n",
        "f1_class_2_digits = digits_to_list(f1_class_2_rounded)\n",
        "\n",
        "# Print digits for drag-and-drop (each metric should have 5 digits: X.XXX  [X,X,X,X,X])\n",
        "print(\"\\nDigits for Accuracy:\", accuracy_digits)\n",
        "print(\"Digits for F-1 score (class = 0):\", f1_class_0_digits)\n",
        "print(\"Digits for F-1 score (class = 1):\", f1_class_1_digits)\n",
        "print(\"Digits for F-1 score (class = 2):\", f1_class_2_digits)"
      ],
      "metadata": {
        "id": "yzYlfbb3i4HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ?  "
      ],
      "metadata": {
        "id": "WBIhoRnCjuTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset from CSV file\n",
        "data = pd.read_csv('Question7_Final_CP.csv')\n",
        "\n",
        "# Define category-specific parameters for Age Group (as provided in your previous request)\n",
        "category_specific_params_age = {\n",
        "    \"18-24\": {\"rho\": 0.020, \"m\": 5},\n",
        "    \"25-34\": {\"rho\": 0.025, \"m\": 6},\n",
        "    \"35-44\": {\"rho\": 0.030, \"m\": 5},\n",
        "    \"45-54\": {\"rho\": 0.022, \"m\": 4},\n",
        "    \"55-64\": {\"rho\": 0.018, \"m\": 5},\n",
        "    \"65+\": {\"rho\": 0.015, \"m\": 6},\n",
        "}\n",
        "\n",
        "# Default clustering parameters for other categories (you can adjust these)\n",
        "default_params = {\"rho\": 0.020, \"m\": 5}  # Default values for Race/Ethnicity, Gender, Income Level\n",
        "\n",
        "# Categories to analyze\n",
        "categories = ['Age Group', 'Race/Ethnicity', 'Gender', 'Income Level']\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Total sample size\n",
        "total_sample_size = len(data)\n",
        "\n",
        "# Calculate for each category\n",
        "for category in categories:\n",
        "    # Get unique values in the category\n",
        "    unique_values = data[category].unique()\n",
        "\n",
        "    for value in unique_values:\n",
        "        # Filter data for this specific category value\n",
        "        count = len(data[data[category] == value])\n",
        "\n",
        "        # 1. Count\n",
        "        count_value = count\n",
        "\n",
        "        # 2. Proportion (p)\n",
        "        proportion = count_value / total_sample_size\n",
        "\n",
        "        # 3. Standard Error (SE)\n",
        "        se = np.sqrt((proportion * (1 - proportion)) / total_sample_size)\n",
        "\n",
        "        # 4. 95% Confidence Interval (CI)\n",
        "        z = 1.96  # For 95% confidence level\n",
        "        ci_lower = proportion - z * se\n",
        "        ci_upper = proportion + z * se\n",
        "\n",
        "        # 5. Get rho and m for the category\n",
        "        if category == 'Age Group':\n",
        "            params = category_specific_params_age.get(value, default_params)\n",
        "        else:\n",
        "            params = default_params  # Use default for Race/Ethnicity, Gender, Income Level\n",
        "\n",
        "        rho = params[\"rho\"]\n",
        "        m = params[\"m\"]\n",
        "\n",
        "        # 6. Design Effect (DEFF)\n",
        "        deff = 1 + rho * (m - 1)\n",
        "\n",
        "        # 7. Adjusted Standard Error (SE_adj)\n",
        "        se_adj = se * np.sqrt(deff)\n",
        "\n",
        "        # 8. Updated 95% Confidence Interval with adjusted SE\n",
        "        ci_lower_adj = proportion - z * se_adj\n",
        "        ci_upper_adj = proportion + z * se_adj\n",
        "\n",
        "        # Store results\n",
        "        results[(category, value)] = {\n",
        "            \"Count\": count_value,\n",
        "            \"Proportion (p)\": proportion,\n",
        "            \"Standard Error (SE)\": se,\n",
        "            \"95% CI (Unadjusted)\": (ci_lower, ci_upper),\n",
        "            \"rho\": rho,\n",
        "            \"m\": m,\n",
        "            \"Design Effect (DEFF)\": deff,\n",
        "            \"Adjusted Standard Error (SE_adj)\": se_adj,\n",
        "            \"95% CI (Adjusted)\": (ci_lower_adj, ci_upper_adj)\n",
        "        }\n",
        "\n",
        "# Print results for each category and value\n",
        "for (cat, value), metrics in results.items():\n",
        "    print(f\"\\n{cat}: {value}\")\n",
        "    print(f\"1. Count: {metrics['Count']}\")\n",
        "    print(f\"2. Proportion (p): {metrics['Proportion (p)']:.4f}\")\n",
        "    print(f\"3. Standard Error (SE): {metrics['Standard Error (SE)']:.4f}\")\n",
        "    print(f\"4. 95% CI (Unadjusted): [{metrics['95% CI (Unadjusted)'][0]:.4f}, {metrics['95% CI (Unadjusted)'][1]:.4f}]\")\n",
        "    print(f\"5. Intraclass Correlation (rho): {metrics['rho']}\")\n",
        "    print(f\"6. Average Cluster Size (m): {metrics['m']}\")\n",
        "    print(f\"7. Design Effect (DEFF): {metrics['Design Effect (DEFF)']:.4f}\")\n",
        "    print(f\"8. Adjusted Standard Error (SE_adj): {metrics['Adjusted Standard Error (SE_adj)']:.4f}\")\n",
        "    print(f\"9. 95% CI (Adjusted): [{metrics['95% CI (Adjusted)'][0]:.4f}, {metrics['95% CI (Adjusted)'][1]:.4f}]\")\n",
        ""
      ],
      "metadata": {
        "id": "Q_fFw1qdjnYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age Group: 65+\n",
        "1. Count: 153\n",
        "2. Proportion (p): 0.1020\n",
        "3. Standard Error (SE): 0.0078\n",
        "4. 95% CI (Unadjusted): [0.0867, 0.1173]\n",
        "5. Intraclass Correlation (rho): 0.015\n",
        "6. Average Cluster Size (m): 6\n",
        "7. Design Effect (DEFF): 1.0750\n",
        "8. Adjusted Standard Error (SE_adj): 0.0081\n",
        "9. 95% CI (Adjusted): [0.0861, 0.1179]\n",
        "\n",
        "Age Group: 35-44\n",
        "1. Count: 336\n",
        "2. Proportion (p): 0.2240\n",
        "3. Standard Error (SE): 0.0108\n",
        "4. 95% CI (Unadjusted): [0.2029, 0.2451]\n",
        "5. Intraclass Correlation (rho): 0.03\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.1200\n",
        "8. Adjusted Standard Error (SE_adj): 0.0114\n",
        "9. 95% CI (Adjusted): [0.2017, 0.2463]\n",
        "\n",
        "Age Group: 18-24\n",
        "1. Count: 227\n",
        "2. Proportion (p): 0.1513\n",
        "3. Standard Error (SE): 0.0093\n",
        "4. 95% CI (Unadjusted): [0.1332, 0.1695]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0096\n",
        "9. 95% CI (Adjusted): [0.1325, 0.1702]\n",
        "\n",
        "Age Group: 45-54\n",
        "1. Count: 188\n",
        "2. Proportion (p): 0.1253\n",
        "3. Standard Error (SE): 0.0085\n",
        "4. 95% CI (Unadjusted): [0.1086, 0.1421]\n",
        "5. Intraclass Correlation (rho): 0.022\n",
        "6. Average Cluster Size (m): 4\n",
        "7. Design Effect (DEFF): 1.0660\n",
        "8. Adjusted Standard Error (SE_adj): 0.0088\n",
        "9. 95% CI (Adjusted): [0.1080, 0.1426]\n",
        "\n",
        "Age Group: 25-34\n",
        "1. Count: 384\n",
        "2. Proportion (p): 0.2560\n",
        "3. Standard Error (SE): 0.0113\n",
        "4. 95% CI (Unadjusted): [0.2339, 0.2781]\n",
        "5. Intraclass Correlation (rho): 0.025\n",
        "6. Average Cluster Size (m): 6\n",
        "7. Design Effect (DEFF): 1.1250\n",
        "8. Adjusted Standard Error (SE_adj): 0.0120\n",
        "9. 95% CI (Adjusted): [0.2326, 0.2794]\n",
        "\n",
        "Age Group: 55-64\n",
        "1. Count: 212\n",
        "2. Proportion (p): 0.1413\n",
        "3. Standard Error (SE): 0.0090\n",
        "4. 95% CI (Unadjusted): [0.1237, 0.1590]\n",
        "5. Intraclass Correlation (rho): 0.018\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0720\n",
        "8. Adjusted Standard Error (SE_adj): 0.0093\n",
        "9. 95% CI (Adjusted): [0.1231, 0.1596]\n",
        "\n",
        "Race/Ethnicity: Mexican\n",
        "1. Count: 121\n",
        "2. Proportion (p): 0.0807\n",
        "3. Standard Error (SE): 0.0070\n",
        "4. 95% CI (Unadjusted): [0.0669, 0.0944]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0073\n",
        "9. 95% CI (Adjusted): [0.0663, 0.0950]\n",
        "\n",
        "Race/Ethnicity: Other Hispanic\n",
        "1. Count: 51\n",
        "2. Proportion (p): 0.0340\n",
        "3. Standard Error (SE): 0.0047\n",
        "4. 95% CI (Unadjusted): [0.0248, 0.0432]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0049\n",
        "9. 95% CI (Adjusted): [0.0245, 0.0435]\n",
        "\n",
        "Race/Ethnicity: White\n",
        "1. Count: 1072\n",
        "2. Proportion (p): 0.7147\n",
        "3. Standard Error (SE): 0.0117\n",
        "4. 95% CI (Unadjusted): [0.6918, 0.7375]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0121\n",
        "9. 95% CI (Adjusted): [0.6909, 0.7384]\n",
        "\n",
        "Race/Ethnicity: Black\n",
        "1. Count: 175\n",
        "2. Proportion (p): 0.1167\n",
        "3. Standard Error (SE): 0.0083\n",
        "4. 95% CI (Unadjusted): [0.1004, 0.1329]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0086\n",
        "9. 95% CI (Adjusted): [0.0998, 0.1335]\n",
        "\n",
        "Race/Ethnicity: Other\n",
        "1. Count: 81\n",
        "2. Proportion (p): 0.0540\n",
        "3. Standard Error (SE): 0.0058\n",
        "4. 95% CI (Unadjusted): [0.0426, 0.0654]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0061\n",
        "9. 95% CI (Adjusted): [0.0421, 0.0659]\n",
        "\n",
        "Gender: Female\n",
        "1. Count: 752\n",
        "2. Proportion (p): 0.5013\n",
        "3. Standard Error (SE): 0.0129\n",
        "4. 95% CI (Unadjusted): [0.4760, 0.5266]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0134\n",
        "9. 95% CI (Adjusted): [0.4750, 0.5276]\n",
        "\n",
        "Gender: Male\n",
        "1. Count: 748\n",
        "2. Proportion (p): 0.4987\n",
        "3. Standard Error (SE): 0.0129\n",
        "4. 95% CI (Unadjusted): [0.4734, 0.5240]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0134\n",
        "9. 95% CI (Adjusted): [0.4724, 0.5250]\n",
        "\n",
        "Income Level: Middle\n",
        "1. Count: 761\n",
        "2. Proportion (p): 0.5073\n",
        "3. Standard Error (SE): 0.0129\n",
        "4. 95% CI (Unadjusted): [0.4820, 0.5326]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0134\n",
        "9. 95% CI (Adjusted): [0.4810, 0.5336]\n",
        "\n",
        "Income Level: Low\n",
        "1. Count: 447\n",
        "2. Proportion (p): 0.2980\n",
        "3. Standard Error (SE): 0.0118\n",
        "4. 95% CI (Unadjusted): [0.2749, 0.3211]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0123\n",
        "9. 95% CI (Adjusted): [0.2739, 0.3221]\n",
        "\n",
        "Income Level: High\n",
        "1. Count: 292\n",
        "2. Proportion (p): 0.1947\n",
        "3. Standard Error (SE): 0.0102\n",
        "4. 95% CI (Unadjusted): [0.1746, 0.2147]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0106\n",
        "9. 95% CI (Adjusted): [0.1738, 0.2155]"
      ],
      "metadata": {
        "id": "k1wxx0c7jpa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "strCustomerName, strEmail, strSKU, prodItem, and strOTP  Hungarian\n",
        "SKU, OTP  Acronym\n",
        "AddOrderItem, customerID params  Pascal"
      ],
      "metadata": {
        "id": "0heGah4GuH2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "A  Integration Testing (since it involves component interaction).\n",
        "B  Stress Testing (since it evaluates system stability under high loads).\n",
        "#       \n",
        "A Integration Testing (since it involves component interaction).\n",
        "B Stress Testing (since it evaluates system stability under high loads).\n",
        "class TestOrder\tIntegration Testing\n",
        "def test_order_under_repeated_processing\tStress Testing / Stability Testing"
      ],
      "metadata": {
        "id": "JNAD2hIXkcaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "A\t- Ok Case (Correct implementation of Bubble Sort, no syntax or logical errors)\n",
        "B\t- Missing Semicolon (Missing semicolon after int temp = arr[j] causes compilation error)\n",
        "C\t- Incorrect Comparison Index (arr[j] > arr[i] should be arr[j] > arr[j+1])\n",
        "D\t- Index Out of Range Bug (j <= n - i - 1 should be j < n - i - 1, avoids accessing arr[j+1] out of bounds)\n",
        "E\t- Undefined Variable (return fib; should be return c;, fib is not defined)\n",
        "F\t- Ok Case (Correct Fibonacci sequence implementation)\n",
        "G\t- Missing Semicolon (Missing semicolon after throw new ArgumentException(\"Input must be non-negative\"))\n",
        "H\t- Ok Case (Correct Fibonacci implementation, expected output 55)"
      ],
      "metadata": {
        "id": "n_6ruqzhleca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}