{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgEheCqEoCui",
        "outputId": "7c5896b6-0dc3-4305-ce4a-19aaa7f0c268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data with 16 records\n",
            "First few rows:\n",
            "   Unnamed: 0  Case  Stratum  Cluster  Variable\n",
            "0         NaN     1        1        1      11.5\n",
            "1         NaN     2        1        1      29.0\n",
            "2         NaN     3        1        2      35.6\n",
            "3         NaN     4        1        2      64.7\n",
            "4         NaN     5        2        3      19.2\n",
            "\n",
            "==== Simple Random Sampling Analysis ====\n",
            "1) Mean (SRS): 50.60\n",
            "2) Standard Error (SRS): 6.8851\n",
            "3) 95% Confidence Interval (SRS):\n",
            "   Upper limit: 64.6455\n",
            "   Lower limit: 36.5545\n",
            "\n",
            "==== Clustered Random Sampling Analysis ====\n",
            "1) Mean (Clustered): 50.60\n",
            "2) Standard Error (Clustered): 7.6243\n",
            "3) Design Effect (d-value): 1.1074\n",
            "4) d-squared: 1.2263\n",
            "5) Intraclass correlation (roh): 0.2263\n",
            "6) Effective sample size (Neff): 13.0477\n",
            "\n",
            "==== Summary of Results (Rounded as Required) ====\n",
            "srs_mean: 50.6\n",
            "srs_se: 6.8851\n",
            "ci_upper: 64.6455\n",
            "ci_lower: 36.5545\n",
            "crs_mean: 50.6\n",
            "crs_se: 7.6243\n",
            "d_value: 1.1074\n",
            "d_squared: 1.2263\n",
            "roh: 0.2263\n",
            "Neff: 13.0477\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#1 task\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "def load_data(file_path: str) -> pd.DataFrame:\n",
        "    try:\n",
        "        data = pd.read_excel(file_path, engine='openpyxl')\n",
        "        print(f\"Successfully loaded data with {len(data)} records\")\n",
        "        print(\"First few rows:\")\n",
        "        print(data.head())\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading Excel file: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "def prepare_data(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    required_columns = ['Case', 'Stratum', 'Cluster', 'Variable']\n",
        "    for column in required_columns:\n",
        "        if column not in data.columns:\n",
        "            print(f\"Error: '{column}' column not found in the dataset.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    data['response'] = data['Variable']\n",
        "    data['cluster_id'] = data['Cluster']\n",
        "    return data\n",
        "\n",
        "\n",
        "def simple_random_sampling(data: pd.DataFrame) -> Dict[str, float]:\n",
        "    print(\"\\n==== Simple Random Sampling Analysis ====\")\n",
        "    srs_mean = data['response'].mean()\n",
        "    print(f\"1) Mean (SRS): {srs_mean:.2f}\")\n",
        "\n",
        "    n = len(data)\n",
        "    srs_std = data['response'].std(ddof=1)\n",
        "    srs_se = srs_std / np.sqrt(n)\n",
        "    print(f\"2) Standard Error (SRS): {srs_se:.4f}\")\n",
        "\n",
        "    t_value = 2.04\n",
        "    margin_of_error = t_value * srs_se\n",
        "    ci_upper = srs_mean + margin_of_error\n",
        "    ci_lower = srs_mean - margin_of_error\n",
        "    print(f\"3) 95% Confidence Interval (SRS):\")\n",
        "    print(f\"   Upper limit: {ci_upper:.4f}\")\n",
        "    print(f\"   Lower limit: {ci_lower:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'srs_mean': srs_mean,\n",
        "        'srs_se': srs_se,\n",
        "        'ci_upper': ci_upper,\n",
        "        'ci_lower': ci_lower\n",
        "    }\n",
        "\n",
        "\n",
        "def clustered_random_sampling(data: pd.DataFrame, srs_se: float) -> Dict[str, float]:\n",
        "    print(\"\\n==== Clustered Random Sampling Analysis ====\")\n",
        "    cluster_means = data.groupby('cluster_id')['response'].mean()\n",
        "    crs_mean = cluster_means.mean()\n",
        "    print(f\"1) Mean (Clustered): {crs_mean:.2f}\")\n",
        "\n",
        "    M = len(cluster_means)\n",
        "    cluster_var = np.var(cluster_means, ddof=1)\n",
        "    crs_se = np.sqrt(cluster_var / M)\n",
        "    print(f\"2) Standard Error (Clustered): {crs_se:.4f}\")\n",
        "\n",
        "    d_value = crs_se / srs_se\n",
        "    print(f\"3) Design Effect (d-value): {d_value:.4f}\")\n",
        "\n",
        "    d_squared = d_value ** 2\n",
        "    print(f\"4) d-squared: {d_squared:.4f}\")\n",
        "\n",
        "    n_avg = data.groupby('cluster_id').size().mean()\n",
        "    roh = (d_squared - 1) / (n_avg - 1) if n_avg > 1 else 0\n",
        "    print(f\"5) Intraclass correlation (roh): {roh:.4f}\")\n",
        "\n",
        "    Neff = len(data) / d_squared\n",
        "    print(f\"6) Effective sample size (Neff): {Neff:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'crs_mean': crs_mean,\n",
        "        'crs_se': crs_se,\n",
        "        'd_value': d_value,\n",
        "        'd_squared': d_squared,\n",
        "        'roh': roh,\n",
        "        'Neff': Neff\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_comparison(srs_mean: float, crs_mean: float, srs_se: float, crs_se: float):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(['SRS Mean', 'Clustered Mean'], [srs_mean, crs_mean])\n",
        "    plt.errorbar(['SRS Mean', 'Clustered Mean'], [srs_mean, crs_mean],\n",
        "                 yerr=[srs_se, crs_se], fmt='o', color='black')\n",
        "    plt.title('Comparison of SRS and Clustered Random Sampling')\n",
        "    plt.ylabel('Mean Value')\n",
        "    plt.savefig('sampling_comparison.png')\n",
        "\n",
        "\n",
        "def analyze_survey_data(excel_file_path: str) -> Dict[str, Any]:\n",
        "    data = load_data(excel_file_path)\n",
        "    if data.empty:\n",
        "        return {}\n",
        "\n",
        "    data = prepare_data(data)\n",
        "    if data.empty:\n",
        "        return {}\n",
        "\n",
        "    srs_results = simple_random_sampling(data)\n",
        "    crs_results = clustered_random_sampling(data, srs_results['srs_se'])\n",
        "\n",
        "    plot_comparison(srs_results['srs_mean'], crs_results['crs_mean'],\n",
        "                    srs_results['srs_se'], crs_results['crs_se'])\n",
        "\n",
        "    results = {**srs_results, **crs_results}\n",
        "    return {k: round(v, 4) for k, v in results.items()}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = analyze_survey_data('Question1_Final_CP.xlsx')\n",
        "    if results:\n",
        "        print(\"\\n==== Summary of Results (Rounded as Required) ====\")\n",
        "        for key, value in results.items():\n",
        "            print(f\"{key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 task\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the dataset from CSV file (use the filename as is, since it's in the same directory)\n",
        "data = pd.read_csv('Question2_Dataset.csv')\n",
        "\n",
        "# Prepare the features (X) and target (y)\n",
        "X = data[['X1', 'X2', 'X1^2', 'X1^3', 'X2^2', 'X2^3', 'X1*X2', 'X1^2*X2']].values\n",
        "y = data['Y'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the features (Z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_normalized, y)\n",
        "\n",
        "# Get the initial theta parameters (including bias)\n",
        "initial_theta = np.zeros(X.shape[1] + 1)  # +1 for bias term (9 parameters total: 1 bias + 8 features)\n",
        "theta = np.concatenate([model.intercept_, model.coef_.flatten()])\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "\n",
        "# Function to calculate cost (Mean Squared Error)\n",
        "def calculate_cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    predictions = X.dot(theta[1:]) + theta[0]  # Shape: (m,)\n",
        "    cost = (1 / (2 * m)) * np.sum((predictions - y.flatten()) ** 2)\n",
        "    return cost\n",
        "\n",
        "\n",
        "# Gradient descent implementation\n",
        "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
        "    m = len(y)  # Number of samples\n",
        "    n = X.shape[1]  # Number of features\n",
        "    cost_history = []\n",
        "\n",
        "    # Ensure y is flattened to avoid shape mismatch\n",
        "    y = y.flatten()  # Now y has shape (m,)\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Calculate predictions (shape: (m,))\n",
        "        predictions = X.dot(theta[1:]) + theta[0]  # theta[1:] has shape (n,), X has shape (m,n)\n",
        "        errors = predictions - y  # Shape: (m,)\n",
        "\n",
        "        # Update bias (theta[0]) - sum over all examples\n",
        "        theta[0] = theta[0] - (learning_rate / m) * np.sum(errors)\n",
        "\n",
        "        # Update feature coefficients (theta[1:]) - calculate gradient correctly\n",
        "        gradient_features = (1 / m) * X.T.dot(errors)  # Shape: (n,) where n=8\n",
        "        theta[1:] = theta[1:] - learning_rate * gradient_features  # Both shapes (n,)\n",
        "\n",
        "        cost = calculate_cost(X, y, theta)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "# Run gradient descent for different iterations\n",
        "n_10_results = gradient_descent(X_normalized, y, initial_theta.copy(), learning_rate, 10)\n",
        "n_100_results = gradient_descent(X_normalized, y, initial_theta.copy(), learning_rate, 100)\n",
        "n_1000_results = gradient_descent(X_normalized, y, initial_theta.copy(), learning_rate, 1000)\n",
        "\n",
        "# Print results in the required format (rounded to integers)\n",
        "print(\"n=10\")\n",
        "print(\"Cost Function (Round):\", round(calculate_cost(X_normalized, y, n_10_results[0])))\n",
        "print(\"Optimal Theta parameter (Round):\", [round(x) for x in n_10_results[0]])\n",
        "\n",
        "print(\"\\nn=100\")\n",
        "print(\"Cost Function (Round):\", round(calculate_cost(X_normalized, y, n_100_results[0])))\n",
        "print(\"Optimal Theta parameter (Round):\", [round(x) for x in n_100_results[0]])\n",
        "\n",
        "print(\"\\nn=1000\")\n",
        "print(\"Cost Function (Round):\", round(calculate_cost(X_normalized, y, n_1000_results[0])))\n",
        "print(\"Optimal Theta parameter (Round):\", [round(x) for x in n_1000_results[0]])\n"
      ],
      "metadata": {
        "id": "-cgd06CkgADz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "n=10\n",
        "Cost Function (Round): 895241\n",
        "Optimal Theta parameter (Round): [2167, -54, 839, -47, -31, 1001, 1080, 436, 283]\n",
        "\n",
        "n=100\n",
        "Cost Function (Round): 42271\n",
        "Optimal Theta parameter (Round): [3328, 50, 230, 125, 192, 1244, 1897, 18, 63]\n",
        "\n",
        "n=1000\n",
        "Cost Function (Round): 1261\n",
        "Optimal Theta parameter (Round): [3328, -17, -520, 119, 228, 1231, 2651, -64, 200]\n"
      ],
      "metadata": {
        "id": "KRCFY1LNiXBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3 task\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the dataset from CSV file\n",
        "data = pd.read_csv('Question3_Final_CP.csv')\n",
        "\n",
        "# Prepare the features (X) and target (y)\n",
        "X = data[['X1', 'X2', 'X3']].values  # 3 input features\n",
        "y = data['Y'].values.reshape(-1, 1)  # Binary output (0 or 1)\n",
        "\n",
        "# Normalize the features (Z-score normalization: Z = (X - mu)/std)\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Add intercept term (bias) to X\n",
        "X_normalized = np.c_[np.ones(X_normalized.shape[0]), X_normalized]  # Shape: (n_samples, 4) with bias\n",
        "\n",
        "# Initial theta parameters (0 for all, including bias)\n",
        "n_features = X_normalized.shape[1]  # 4 (1 bias + 3 features)\n",
        "theta = np.zeros((n_features, 1))  # Initial theta 2D: [[0], [0], [0], [0]]\n",
        "\n",
        "\n",
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "# Cost function with L2 regularization\n",
        "def compute_cost(X, y, theta, lambda_reg):\n",
        "    m = len(y)\n",
        "    h = sigmoid(X.dot(theta))  # Predictions\n",
        "    # Cost without regularization\n",
        "    cost = (-1 / m) * (y.T.dot(np.log(h + 1e-15)) + (1 - y).T.dot(np.log(1 - h + 1e-15)))\n",
        "    # Add L2 regularization (ridge) - exclude theta[0] (bias) from regularization\n",
        "    reg_term = (lambda_reg / (2 * m)) * np.sum(theta[1:] ** 2)\n",
        "    return cost[0][0] + reg_term  # Return scalar\n",
        "\n",
        "\n",
        "# Gradient descent with L2 regularization\n",
        "def gradient_descent(X, y, theta, alpha, lambda_reg, iterations):\n",
        "    m = len(y)\n",
        "    cost_history = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        h = sigmoid(X.dot(theta))  # Predictions\n",
        "        # Gradient without regularization\n",
        "        gradient = (1 / m) * X.T.dot(h - y)  # Shape: (n_features, 1)\n",
        "        # Add L2 regularization gradient (exclude theta[0])\n",
        "        gradient[1:] += (lambda_reg / m) * theta[1:]\n",
        "        # Update theta\n",
        "        theta = theta - alpha * gradient\n",
        "        cost = compute_cost(X, y, theta, lambda_reg)\n",
        "        cost_history.append(cost)\n",
        "\n",
        "    return theta, cost_history\n",
        "\n",
        "\n",
        "# Parameters for different cases\n",
        "cases = [\n",
        "    (100, 0.1, 0.1),  # N=100, alpha=0.1, lambda=0.1\n",
        "    (1000, 0.2, 1),  # N=1000, alpha=0.2, lambda=1\n",
        "    (10000, 0.3, 10)  # N=10000, alpha=0.3, lambda=10\n",
        "]\n",
        "\n",
        "# Run logistic regression for each case\n",
        "for n_iterations, alpha, lambda_reg in cases:\n",
        "    theta_init = np.zeros((n_features, 1))\n",
        "    final_theta, _ = gradient_descent(X_normalized, y, theta_init, alpha, lambda_reg, n_iterations)\n",
        "\n",
        "    # Compute cost (rounded up to 2 decimal places after floating point)\n",
        "    cost = compute_cost(X_normalized, y, final_theta, lambda_reg)\n",
        "    cost_rounded = round(cost, 2)  # Round to 2 decimal places\n",
        "\n",
        "    # Find maximum theta value (rounded up to 2 decimal places after floating point)\n",
        "    max_theta = np.max(np.abs(final_theta))  # Use absolute value for maximum\n",
        "    max_theta_rounded = round(max_theta, 2)  # Round to 2 decimal places\n",
        "\n",
        "    print(f\"N={n_iterations}, alpha={alpha}, lambda={lambda_reg}\")\n",
        "    print(f\"Cost function (rounded up to 2 digits after floating point): {cost_rounded}\")\n",
        "    print(f\"Optimal theta parameter maximum value (rounded up to 2 digits after floating point): {max_theta_rounded}\\n\")\n",
        "\n",
        "# Special case: After 10,000 iterations, alpha=0.3, lambda=10, predict first 10 rows with threshold=0.5\n",
        "theta_final, _ = gradient_descent(X_normalized, y, np.zeros((n_features, 1)), 0.3, 10, 10000)\n",
        "predictions = sigmoid(X_normalized.dot(theta_final))  # Predict probabilities for all rows\n",
        "first_10_predictions = (predictions[:10] >= 0.5).astype(int)  # Apply threshold 0.5, convert to 0 or 1\n",
        "number_of_ones = np.sum(first_10_predictions)  # Count number of 1s in first 10 rows\n",
        "\n",
        "print(f\"Number of ones in the first 10 rows of predictions (threshold=0.5): {int(number_of_ones)}\")\n"
      ],
      "metadata": {
        "id": "JmjyJEvSia5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "N=100, alpha=0.1, lambda=0.1\n",
        "Cost function (rounded up to 2 digits after floating point): 0.28\n",
        "Optimal theta parameter maximum value (rounded up to 2 digits after floating point): 1.61\n",
        "\n",
        "N=1000, alpha=0.2, lambda=1\n",
        "Cost function (rounded up to 2 digits after floating point): 0.16\n",
        "Optimal theta parameter maximum value (rounded up to 2 digits after floating point): 4.59\n",
        "\n",
        "N=10000, alpha=0.3, lambda=10\n",
        "Cost function (rounded up to 2 digits after floating point): 0.33\n",
        "Optimal theta parameter maximum value (rounded up to 2 digits after floating point): 2.02\n",
        "\n",
        "Number of ones in the first 10 rows of predictions (threshold=0.5): 6"
      ],
      "metadata": {
        "id": "OMCbwdaXiqfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4 TASK\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "\n",
        "# Example input (flattened image vectors) - replace with your actual normalized data\n",
        "X = np.array([[0.25, 0.5, 0.75, 1.0],  # Dog image example (simplified)\n",
        "              [0.1, 0.3, 0.5, 0.7]])  # Cat image example (simplified)\n",
        "\n",
        "# Example output (1 for dog, 0 for cat)\n",
        "y = np.array([[1], [0]])\n",
        "\n",
        "# Network architecture\n",
        "input_layer_size = 4  # Number of features\n",
        "hidden_layer1_size = 7  # First hidden layer neurons\n",
        "hidden_layer2_size = 5  # Second hidden layer neurons\n",
        "hidden_layer3_size = 3  # Third hidden layer neurons\n",
        "output_layer_size = 1  # Binary classification (dog/cat)\n",
        "\n",
        "# Fixed initial weights and biases (as provided)\n",
        "W1 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
        "               [0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4],\n",
        "               [1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1],\n",
        "               [2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8]])\n",
        "b1 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]])\n",
        "\n",
        "W2 = np.array([[0.2, 0.3, 0.4, 0.5, 0.6],\n",
        "               [0.7, 0.8, 0.9, 1.0, 1.1],\n",
        "               [1.2, 1.3, 1.4, 1.5, 1.6],\n",
        "               [1.7, 1.8, 1.9, 2.0, 2.1],\n",
        "               [2.2, 2.3, 2.4, 2.5, 2.6],\n",
        "               [2.7, 2.8, 2.9, 3.0, 3.1],\n",
        "               [3.2, 3.3, 3.4, 3.5, 3.6]])\n",
        "b2 = np.array([[0.1, 0.2, 0.3, 0.4, 0.5]])\n",
        "\n",
        "W3 = np.array([[0.2, 0.3, 0.4],\n",
        "               [0.5, 0.6, 0.7],\n",
        "               [0.8, 0.9, 1.0],\n",
        "               [1.1, 1.2, 1.3],\n",
        "               [1.4, 1.5, 1.6]])\n",
        "b3 = np.array([[0.1, 0.2, 0.3]])\n",
        "\n",
        "W4 = np.array([[0.2], [0.3], [0.4]])\n",
        "b4 = np.array([[0.1]])\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "# Lists to store metrics for final analysis\n",
        "a4_history = []\n",
        "W4_history = []\n",
        "W3_history = []\n",
        "loss_history = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = tanh(z1)  # Tanh activation for hidden layer 1\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = tanh(z2)  # Tanh activation for hidden layer 2\n",
        "\n",
        "    z3 = np.dot(a2, W3) + b3\n",
        "    a3 = tanh(z3)  # Tanh activation for hidden layer 3\n",
        "\n",
        "    z4 = np.dot(a3, W4) + b4\n",
        "    a4 = sigmoid(z4)  # Sigmoid activation for output layer\n",
        "\n",
        "    # Compute loss (Mean Absolute Error - MAE)\n",
        "    error = y - a4\n",
        "    loss = np.mean(np.abs(error))\n",
        "    loss_history.append(loss)\n",
        "\n",
        "    # Store history for final analysis\n",
        "    a4_history.append(a4.copy())\n",
        "    W4_history.append(W4.copy())\n",
        "    W3_history.append(W3.copy())\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a4 = error * sigmoid_derivative(a4)  # Derivative of sigmoid for output layer\n",
        "    d_W4 = np.dot(a3.T, d_a4) * learning_rate\n",
        "    d_b4 = np.sum(d_a4, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    d_a3 = np.dot(d_a4, W4.T) * tanh_derivative(a3)  # Derivative of Tanh for hidden layer 3\n",
        "    d_W3 = np.dot(a2.T, d_a3) * learning_rate\n",
        "    d_b3 = np.sum(d_a3, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    d_a2 = np.dot(d_a3, W3.T) * tanh_derivative(a2)  # Derivative of Tanh for hidden layer 2\n",
        "    d_W2 = np.dot(a1.T, d_a2) * learning_rate\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * tanh_derivative(a1)  # Derivative of Tanh for hidden layer 1\n",
        "    d_W1 = np.dot(X.T, d_a1) * learning_rate\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Update weights and biases\n",
        "    W4 += d_W4\n",
        "    b4 += d_b4\n",
        "    W3 += d_W3\n",
        "    b3 += d_b3\n",
        "    W2 += d_W2\n",
        "    b2 += d_b2\n",
        "    W1 += d_W1\n",
        "    b1 += d_b1\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Final predictions (probabilities for each input)\n",
        "y_pred = a4\n",
        "print(\"Final Predictions:\", y_pred)\n",
        "\n",
        "# Compute required metrics after 10,000 epochs\n",
        "# a4 = [value1, value2, ...] (final activations of output layer, rounded to 3 decimal places)\n",
        "a4_final = a4_history[-1]  # Last activation values\n",
        "a4_rounded = np.round(a4_final, 3)  # Round to 3 digits after floating point\n",
        "print(f\"a4 = {a4_rounded.flatten().tolist()}\")\n",
        "\n",
        "# a3_min (minimum activation in hidden layer 3, rounded to 3 decimal places)\n",
        "a3_final = a3  # Final activations of hidden layer 3\n",
        "a3_min = np.min(a3_final)\n",
        "a3_min_rounded = round(a3_min, 3)  # Round to 3 digits after floating point\n",
        "print(f\"a3_min = {a3_min_rounded}\")\n",
        "\n",
        "# W4_max (maximum weight in W4, rounded to 2 decimal places)\n",
        "W4_max = np.max(np.abs(W4))  # Use absolute value for maximum\n",
        "W4_max_rounded = round(W4_max, 2)  # Round to 2 digits after floating point\n",
        "print(f\"W4_max = {W4_max_rounded}\")\n",
        "\n",
        "# W3_min (minimum weight in W3, rounded to 2 decimal places)\n",
        "W3_min = np.min(np.abs(W3))  # Use absolute value for minimum\n",
        "W3_min_rounded = round(W3_min, 2)  # Round to 2 digits after floating point\n",
        "print(f\"W3_min = {W3_min_rounded}\")\n",
        "\n",
        "# Loss after 10,000 epochs (rounded to 2 decimal places)\n",
        "loss_final = loss_history[-1]  # Last loss value\n",
        "loss_rounded = round(loss_final, 2)  # Round to 2 digits after floating point\n",
        "print(f\"Loss after 10000 epochs: {loss_rounded}\")\n",
        "\n",
        "# General Conclusion: Predict class for the inputs (dog or cat)\n",
        "threshold = 0.5\n",
        "predictions_binary = (y_pred >= threshold).astype(int)\n",
        "dog_pred = np.any(predictions_binary == 1)  # If any prediction is 1, predict dog\n",
        "cat_pred = np.any(predictions_binary == 0)  # If any prediction is 0, predict cat\n",
        "\n",
        "if dog_pred and not cat_pred:\n",
        "    conclusion = \"NN predicts image of dog\"\n",
        "elif cat_pred and not dog_pred:\n",
        "    conclusion = \"NN predicts image of cat\"\n",
        "else:\n",
        "    conclusion = \"NN can't define correct image class\"\n",
        "\n",
        "print(f\"General Conclusion after 10000 epochs: {conclusion}\")"
      ],
      "metadata": {
        "id": "mEjaD3itit5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Predictions: [[0.5]\n",
        " [0.5]]\n",
        "a4 = [0.5, 0.5]\n",
        "a3_min = 0.999\n",
        "W4_max = 0.15\n",
        "W3_min = 0.19\n",
        "Loss after 10000 epochs: 0.5\n",
        "General Conclusion after 10000 epochs: NN predicts image of dog\n"
      ],
      "metadata": {
        "id": "4YX29x_ziy18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5 task\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read the dataset from CSV file\n",
        "data = pd.read_csv('Question5_Multi_Class_Dataset.csv')\n",
        "\n",
        "# Prepare the features (X) and target (y)\n",
        "X = data[['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5']].values  # 5 input features\n",
        "y = data['Target'].values  # Output variable (0, 1, or 2)\n",
        "\n",
        "# Split the dataset: 70% training, 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression classifier\n",
        "clf_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf_lr.predict(X_test)\n",
        "\n",
        "# Compute metrics for each class (0, 1, 2)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1_class_0 = f1_score(y_test, y_pred, average=None, labels=[0])[0]  # F1 for class 0\n",
        "f1_class_1 = f1_score(y_test, y_pred, average=None, labels=[1])[0]  # F1 for class 1\n",
        "f1_class_2 = f1_score(y_test, y_pred, average=None, labels=[2])[0]  # F1 for class 2\n",
        "\n",
        "# Round all metrics to 3 decimal places\n",
        "accuracy_rounded = round(accuracy, 3)\n",
        "f1_class_0_rounded = round(f1_class_0, 3)\n",
        "f1_class_1_rounded = round(f1_class_1, 3)\n",
        "f1_class_2_rounded = round(f1_class_2, 3)\n",
        "\n",
        "# Print results for verification\n",
        "print(f\"Accuracy: {accuracy_rounded}\")\n",
        "print(f\"F-1 score (class = 0): {f1_class_0_rounded}\")\n",
        "print(f\"F-1 score (class = 1): {f1_class_1_rounded}\")\n",
        "print(f\"F-1 score (class = 2): {f1_class_2_rounded}\")\n",
        "\n",
        "# Convert metrics to strings for digit-by-digit output (for drag-and-drop)\n",
        "def digits_to_list(number):\n",
        "    number_str = f\"{number:.3f}\"  # Format to 3 decimal places\n",
        "    return [int(d) for d in number_str.replace('.', '')]  # Remove decimal and convert to list of integers\n",
        "\n",
        "# Get digits for each metric\n",
        "accuracy_digits = digits_to_list(accuracy_rounded)\n",
        "f1_class_0_digits = digits_to_list(f1_class_0_rounded)\n",
        "f1_class_1_digits = digits_to_list(f1_class_1_rounded)\n",
        "f1_class_2_digits = digits_to_list(f1_class_2_rounded)\n",
        "\n",
        "# Print digits for drag-and-drop (each metric should have 5 digits: X.XXX → [X,X,X,X,X])\n",
        "print(\"\\nDigits for Accuracy:\", accuracy_digits)\n",
        "print(\"Digits for F-1 score (class = 0):\", f1_class_0_digits)\n",
        "print(\"Digits for F-1 score (class = 1):\", f1_class_1_digits)\n",
        "print(\"Digits for F-1 score (class = 2):\", f1_class_2_digits)"
      ],
      "metadata": {
        "id": "yzYlfbb3i4HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Какая задача тут? Нет датасета"
      ],
      "metadata": {
        "id": "WBIhoRnCjuTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset from CSV file\n",
        "data = pd.read_csv('Question7_Final_CP.csv')\n",
        "\n",
        "# Define category-specific parameters for Age Group (as provided in your previous request)\n",
        "category_specific_params_age = {\n",
        "    \"18-24\": {\"rho\": 0.020, \"m\": 5},\n",
        "    \"25-34\": {\"rho\": 0.025, \"m\": 6},\n",
        "    \"35-44\": {\"rho\": 0.030, \"m\": 5},\n",
        "    \"45-54\": {\"rho\": 0.022, \"m\": 4},\n",
        "    \"55-64\": {\"rho\": 0.018, \"m\": 5},\n",
        "    \"65+\": {\"rho\": 0.015, \"m\": 6},\n",
        "}\n",
        "\n",
        "# Default clustering parameters for other categories (you can adjust these)\n",
        "default_params = {\"rho\": 0.020, \"m\": 5}  # Default values for Race/Ethnicity, Gender, Income Level\n",
        "\n",
        "# Categories to analyze\n",
        "categories = ['Age Group', 'Race/Ethnicity', 'Gender', 'Income Level']\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {}\n",
        "\n",
        "# Total sample size\n",
        "total_sample_size = len(data)\n",
        "\n",
        "# Calculate for each category\n",
        "for category in categories:\n",
        "    # Get unique values in the category\n",
        "    unique_values = data[category].unique()\n",
        "\n",
        "    for value in unique_values:\n",
        "        # Filter data for this specific category value\n",
        "        count = len(data[data[category] == value])\n",
        "\n",
        "        # 1. Count\n",
        "        count_value = count\n",
        "\n",
        "        # 2. Proportion (p)\n",
        "        proportion = count_value / total_sample_size\n",
        "\n",
        "        # 3. Standard Error (SE)\n",
        "        se = np.sqrt((proportion * (1 - proportion)) / total_sample_size)\n",
        "\n",
        "        # 4. 95% Confidence Interval (CI)\n",
        "        z = 1.96  # For 95% confidence level\n",
        "        ci_lower = proportion - z * se\n",
        "        ci_upper = proportion + z * se\n",
        "\n",
        "        # 5. Get rho and m for the category\n",
        "        if category == 'Age Group':\n",
        "            params = category_specific_params_age.get(value, default_params)\n",
        "        else:\n",
        "            params = default_params  # Use default for Race/Ethnicity, Gender, Income Level\n",
        "\n",
        "        rho = params[\"rho\"]\n",
        "        m = params[\"m\"]\n",
        "\n",
        "        # 6. Design Effect (DEFF)\n",
        "        deff = 1 + rho * (m - 1)\n",
        "\n",
        "        # 7. Adjusted Standard Error (SE_adj)\n",
        "        se_adj = se * np.sqrt(deff)\n",
        "\n",
        "        # 8. Updated 95% Confidence Interval with adjusted SE\n",
        "        ci_lower_adj = proportion - z * se_adj\n",
        "        ci_upper_adj = proportion + z * se_adj\n",
        "\n",
        "        # Store results\n",
        "        results[(category, value)] = {\n",
        "            \"Count\": count_value,\n",
        "            \"Proportion (p)\": proportion,\n",
        "            \"Standard Error (SE)\": se,\n",
        "            \"95% CI (Unadjusted)\": (ci_lower, ci_upper),\n",
        "            \"rho\": rho,\n",
        "            \"m\": m,\n",
        "            \"Design Effect (DEFF)\": deff,\n",
        "            \"Adjusted Standard Error (SE_adj)\": se_adj,\n",
        "            \"95% CI (Adjusted)\": (ci_lower_adj, ci_upper_adj)\n",
        "        }\n",
        "\n",
        "# Print results for each category and value\n",
        "for (cat, value), metrics in results.items():\n",
        "    print(f\"\\n{cat}: {value}\")\n",
        "    print(f\"1. Count: {metrics['Count']}\")\n",
        "    print(f\"2. Proportion (p): {metrics['Proportion (p)']:.4f}\")\n",
        "    print(f\"3. Standard Error (SE): {metrics['Standard Error (SE)']:.4f}\")\n",
        "    print(f\"4. 95% CI (Unadjusted): [{metrics['95% CI (Unadjusted)'][0]:.4f}, {metrics['95% CI (Unadjusted)'][1]:.4f}]\")\n",
        "    print(f\"5. Intraclass Correlation (rho): {metrics['rho']}\")\n",
        "    print(f\"6. Average Cluster Size (m): {metrics['m']}\")\n",
        "    print(f\"7. Design Effect (DEFF): {metrics['Design Effect (DEFF)']:.4f}\")\n",
        "    print(f\"8. Adjusted Standard Error (SE_adj): {metrics['Adjusted Standard Error (SE_adj)']:.4f}\")\n",
        "    print(f\"9. 95% CI (Adjusted): [{metrics['95% CI (Adjusted)'][0]:.4f}, {metrics['95% CI (Adjusted)'][1]:.4f}]\")\n",
        ""
      ],
      "metadata": {
        "id": "Q_fFw1qdjnYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Age Group: 65+\n",
        "1. Count: 153\n",
        "2. Proportion (p): 0.1020\n",
        "3. Standard Error (SE): 0.0078\n",
        "4. 95% CI (Unadjusted): [0.0867, 0.1173]\n",
        "5. Intraclass Correlation (rho): 0.015\n",
        "6. Average Cluster Size (m): 6\n",
        "7. Design Effect (DEFF): 1.0750\n",
        "8. Adjusted Standard Error (SE_adj): 0.0081\n",
        "9. 95% CI (Adjusted): [0.0861, 0.1179]\n",
        "\n",
        "Age Group: 35-44\n",
        "1. Count: 336\n",
        "2. Proportion (p): 0.2240\n",
        "3. Standard Error (SE): 0.0108\n",
        "4. 95% CI (Unadjusted): [0.2029, 0.2451]\n",
        "5. Intraclass Correlation (rho): 0.03\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.1200\n",
        "8. Adjusted Standard Error (SE_adj): 0.0114\n",
        "9. 95% CI (Adjusted): [0.2017, 0.2463]\n",
        "\n",
        "Age Group: 18-24\n",
        "1. Count: 227\n",
        "2. Proportion (p): 0.1513\n",
        "3. Standard Error (SE): 0.0093\n",
        "4. 95% CI (Unadjusted): [0.1332, 0.1695]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0096\n",
        "9. 95% CI (Adjusted): [0.1325, 0.1702]\n",
        "\n",
        "Age Group: 45-54\n",
        "1. Count: 188\n",
        "2. Proportion (p): 0.1253\n",
        "3. Standard Error (SE): 0.0085\n",
        "4. 95% CI (Unadjusted): [0.1086, 0.1421]\n",
        "5. Intraclass Correlation (rho): 0.022\n",
        "6. Average Cluster Size (m): 4\n",
        "7. Design Effect (DEFF): 1.0660\n",
        "8. Adjusted Standard Error (SE_adj): 0.0088\n",
        "9. 95% CI (Adjusted): [0.1080, 0.1426]\n",
        "\n",
        "Age Group: 25-34\n",
        "1. Count: 384\n",
        "2. Proportion (p): 0.2560\n",
        "3. Standard Error (SE): 0.0113\n",
        "4. 95% CI (Unadjusted): [0.2339, 0.2781]\n",
        "5. Intraclass Correlation (rho): 0.025\n",
        "6. Average Cluster Size (m): 6\n",
        "7. Design Effect (DEFF): 1.1250\n",
        "8. Adjusted Standard Error (SE_adj): 0.0120\n",
        "9. 95% CI (Adjusted): [0.2326, 0.2794]\n",
        "\n",
        "Age Group: 55-64\n",
        "1. Count: 212\n",
        "2. Proportion (p): 0.1413\n",
        "3. Standard Error (SE): 0.0090\n",
        "4. 95% CI (Unadjusted): [0.1237, 0.1590]\n",
        "5. Intraclass Correlation (rho): 0.018\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0720\n",
        "8. Adjusted Standard Error (SE_adj): 0.0093\n",
        "9. 95% CI (Adjusted): [0.1231, 0.1596]\n",
        "\n",
        "Race/Ethnicity: Mexican\n",
        "1. Count: 121\n",
        "2. Proportion (p): 0.0807\n",
        "3. Standard Error (SE): 0.0070\n",
        "4. 95% CI (Unadjusted): [0.0669, 0.0944]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0073\n",
        "9. 95% CI (Adjusted): [0.0663, 0.0950]\n",
        "\n",
        "Race/Ethnicity: Other Hispanic\n",
        "1. Count: 51\n",
        "2. Proportion (p): 0.0340\n",
        "3. Standard Error (SE): 0.0047\n",
        "4. 95% CI (Unadjusted): [0.0248, 0.0432]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0049\n",
        "9. 95% CI (Adjusted): [0.0245, 0.0435]\n",
        "\n",
        "Race/Ethnicity: White\n",
        "1. Count: 1072\n",
        "2. Proportion (p): 0.7147\n",
        "3. Standard Error (SE): 0.0117\n",
        "4. 95% CI (Unadjusted): [0.6918, 0.7375]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0121\n",
        "9. 95% CI (Adjusted): [0.6909, 0.7384]\n",
        "\n",
        "Race/Ethnicity: Black\n",
        "1. Count: 175\n",
        "2. Proportion (p): 0.1167\n",
        "3. Standard Error (SE): 0.0083\n",
        "4. 95% CI (Unadjusted): [0.1004, 0.1329]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0086\n",
        "9. 95% CI (Adjusted): [0.0998, 0.1335]\n",
        "\n",
        "Race/Ethnicity: Other\n",
        "1. Count: 81\n",
        "2. Proportion (p): 0.0540\n",
        "3. Standard Error (SE): 0.0058\n",
        "4. 95% CI (Unadjusted): [0.0426, 0.0654]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0061\n",
        "9. 95% CI (Adjusted): [0.0421, 0.0659]\n",
        "\n",
        "Gender: Female\n",
        "1. Count: 752\n",
        "2. Proportion (p): 0.5013\n",
        "3. Standard Error (SE): 0.0129\n",
        "4. 95% CI (Unadjusted): [0.4760, 0.5266]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0134\n",
        "9. 95% CI (Adjusted): [0.4750, 0.5276]\n",
        "\n",
        "Gender: Male\n",
        "1. Count: 748\n",
        "2. Proportion (p): 0.4987\n",
        "3. Standard Error (SE): 0.0129\n",
        "4. 95% CI (Unadjusted): [0.4734, 0.5240]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0134\n",
        "9. 95% CI (Adjusted): [0.4724, 0.5250]\n",
        "\n",
        "Income Level: Middle\n",
        "1. Count: 761\n",
        "2. Proportion (p): 0.5073\n",
        "3. Standard Error (SE): 0.0129\n",
        "4. 95% CI (Unadjusted): [0.4820, 0.5326]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0134\n",
        "9. 95% CI (Adjusted): [0.4810, 0.5336]\n",
        "\n",
        "Income Level: Low\n",
        "1. Count: 447\n",
        "2. Proportion (p): 0.2980\n",
        "3. Standard Error (SE): 0.0118\n",
        "4. 95% CI (Unadjusted): [0.2749, 0.3211]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0123\n",
        "9. 95% CI (Adjusted): [0.2739, 0.3221]\n",
        "\n",
        "Income Level: High\n",
        "1. Count: 292\n",
        "2. Proportion (p): 0.1947\n",
        "3. Standard Error (SE): 0.0102\n",
        "4. 95% CI (Unadjusted): [0.1746, 0.2147]\n",
        "5. Intraclass Correlation (rho): 0.02\n",
        "6. Average Cluster Size (m): 5\n",
        "7. Design Effect (DEFF): 1.0800\n",
        "8. Adjusted Standard Error (SE_adj): 0.0106\n",
        "9. 95% CI (Adjusted): [0.1738, 0.2155]"
      ],
      "metadata": {
        "id": "k1wxx0c7jpa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "strCustomerName, strEmail, strSKU, prodItem, and strOTP → Hungarian\n",
        "SKU, OTP → Acronym\n",
        "AddOrderItem, customerID params → Pascal"
      ],
      "metadata": {
        "id": "0heGah4GuH2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "A → Integration Testing (since it involves component interaction).\n",
        "B → Stress Testing (since it evaluates system stability under high loads).\n",
        "#не знаю какие методы нужно анализироватью нет скринов\n",
        "A Integration Testing (since it involves component interaction).\n",
        "B Stress Testing (since it evaluates system stability under high loads).\n",
        "class TestOrder\tIntegration Testing\n",
        "def test_order_under_repeated_processing\tStress Testing / Stability Testing"
      ],
      "metadata": {
        "id": "JNAD2hIXkcaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "A\t- Ok Case (Correct implementation of Bubble Sort, no syntax or logical errors)\n",
        "B\t- Missing Semicolon (Missing semicolon after int temp = arr[j] causes compilation error)\n",
        "C\t- Incorrect Comparison Index (arr[j] > arr[i] should be arr[j] > arr[j+1])\n",
        "D\t- Index Out of Range Bug (j <= n - i - 1 should be j < n - i - 1, avoids accessing arr[j+1] out of bounds)\n",
        "E\t- Undefined Variable (return fib; should be return c;, fib is not defined)\n",
        "F\t- Ok Case (Correct Fibonacci sequence implementation)\n",
        "G\t- Missing Semicolon (Missing semicolon after throw new ArgumentException(\"Input must be non-negative\"))\n",
        "H\t- Ok Case (Correct Fibonacci implementation, expected output 55)"
      ],
      "metadata": {
        "id": "n_6ruqzhleca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}